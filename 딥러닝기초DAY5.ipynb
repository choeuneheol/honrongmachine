{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "딥러닝기초DAY5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOcQRuygqw22WMRJZGml8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choeuneheol/honrongmachine/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D%EA%B8%B0%EC%B4%88DAY5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "06.07 9시 1교시\n",
        "\n",
        "12th 유사도\n",
        "\n",
        "\n",
        "###KNN 알고리즘\n",
        "\n",
        "유틀리드거리의문제점\n",
        "\n",
        "2차원에서의최단거리 구할때를 구하기때문에\n",
        "\n",
        "데이터의열정보가 두개일때 쓰인다 \n",
        "\n",
        "유틀리드 거리를 쓸때 임의로 확장을 해서 쓴다.\n",
        "\n",
        "맨하탄디스턴스 실제거리와 가장 유사하다\n",
        "\n",
        "거리 구하는 공식중\n",
        "\n",
        "거리 구할때 유클리드 거리만 쓰는것이 아니다\n",
        "\n",
        "명료성 객관성이 떨어진다\n",
        "\n",
        "missing value가 있어서 최대한 맞추려고 노력하고 최대한 가까운 값을 보고\n",
        "\n",
        "중간값을 보고 정한다\n",
        "\n",
        "거리를 알고 있는데 확률을 알고 싶다면?\n",
        "\n",
        "거리를 가지고 거리를 제곱해서 역수로 뒤집은것\n",
        "\n",
        "전체분의 나 \n",
        "\n",
        "가중치가 적용된 확률\n",
        "\n",
        "k가 1일때는 아일랜드가 떠있다면 오버피팅되어있다 생각해야한다\n",
        "\n",
        "명료성이 떨어진다 수학적인 객관성이 떨어진다\n",
        "\n",
        "근거를 중요시하는 집단에 들어갈때는 제외대상이다\n",
        "\n",
        "열이 많아 질수록 계산량이 증가한다\n",
        "\n",
        "### 군집화\n",
        "\n",
        "모든 데이터를 다 계산한다\n",
        "\n",
        "그중에서 가까운것들끼리 묶는다\n",
        "\n",
        "묶인것은 하나의 점으로 생각한다\n",
        "\n",
        "묶인것을 다시 거리를 젠다 \n",
        "\n",
        "측정해서 묶고 측정해서 묶어서 계층적으로 올라간다\n",
        "\n",
        "이를 계층적 군집화라고 한다 덴드로그램이라고도 한다\n",
        "\n",
        "누가 누가랑 묶이는지 확인할수 있다 \n",
        "\n",
        "이상치 아웃라이어가 어떤것인지 확인할 수 있다.\n",
        "\n",
        "최종적으로는 하나로 묶인다\n",
        "\n",
        "k값을 임의로 넣어줘야 한다\n",
        "\n",
        "내가 만들 군집을 아무곳에 찍고 \n",
        "\n",
        "KNN보다 계산량이 많다. 각각의 군집의 거리를 다 \n",
        "\n",
        "계산하기 때문이다\n",
        "\n",
        "x좌표와 y좌표의 평균을 구하세요는 \n",
        "\n",
        "군집의 중점을 구하라는 뜻이다\n",
        "\n",
        "군집이 이동하면 모든 데이터가 이동한 데이터와의 거리를 \n",
        "\n",
        "다시 계산한다.\n",
        "\n",
        "한곳에 있지 않고 계속 진동을 한다 .\n",
        "\n",
        "스탑조건은? 디스토션이라는 왜곡값을 구한다\n",
        "\n",
        "왜곡값을 구하다 보면 K값을 구하다보면 \n",
        "\n",
        "디스토션 = 거리 제곱의 총합\n",
        "\n",
        "k값이 커질수록 왜곡값은 실제로 줄어든다 \n",
        "\n",
        "완만하게 줄어든 지점을 엘보메서드\n",
        "\n",
        "또다른 방식으로는 실루엣스콧?\n",
        "\n",
        "일반적으로는 실루엣스콧이랑, 엘보메서드랑 같이 쓴다\n",
        "\n",
        "비즈니스 뉴스기사 군집화\n",
        "\n",
        "텍스트 마이닝을 할때는 용어를 먼저 정해야한다\n",
        "\n",
        "커퍼스 - 말뭉치? 한권의 책이라고 생각한다\n",
        "\n",
        "책의 챕터를 다큐먼트 (문서)\n",
        "\n",
        "챕터 안에 글을 텁, 토큰, 워드 이라고 생각한다\n",
        "\n",
        "여기서 책을 주고 주제어를 찾아보려면\n",
        "\n",
        "자주 나오는 단어 범위를 지정해야한다\n",
        "\n",
        "다큐먼트 안에서 빈발도가 높은 단어 \n",
        "\n",
        "다큐먼드 안에서 빈발도가 높다는 의미는? 주제어가 될 가능성이 높다\n",
        "\n",
        "귀납법을 쓰면 주제어가 뒤에 나올수가 있는데\n",
        "\n",
        "인간은 파악하지만 기계는 파악하기 어렵다 두번째 개념으로\n",
        "\n",
        "커퍼스 안에서 빈발하게 나오는 단어 챕터 안에서 나오는 단어를 파악하는\n",
        "\n",
        "문서에서는 빈발하게 나오는 단어 TF\n",
        "\n",
        "커퍼스 안에서 나오는 단어를 IDF\n",
        "\n",
        "TF*IDF 곱해서 나온게 TFIDF 이값이 크면클수록\n",
        "\n",
        "그책의 주제어가 될 가능성이 크다\n",
        "\n",
        "이것이 인포메이션 게인과 비슷하다 수식도 비슷하다.\n",
        "\n",
        "수치형 데이터가 나왔다면 글자와 글자사이의 거리를 잴 수 있다\n",
        "\n",
        "k가 얼마일때 얼마나 좋은 성적을 낼 수 있는가?\n",
        "\n",
        "거기서 기사를 보고 거르면된다\n",
        "\n",
        "군집이 잘 만들어졌는지 다시 해보아야한다 이것을 사후분석이라고 한다\n"
      ],
      "metadata": {
        "id": "0ZwrpFMkdlOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13th\n",
        "\n",
        "ELO Rating 단일랭킹 작업\n",
        "\n",
        "살면서 한번쯤 마주치니 알아둬라\n"
      ],
      "metadata": {
        "id": "ranbwVSKmQGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14th\n",
        "\n",
        "맨하탄디스턴스 실제거리와 가장 유사하다\n",
        "\n",
        "거리 구하는 공식중\n",
        "\n",
        "거리 구할때 유클리드 거리만 쓰는것이 아니다\n",
        "\n",
        "이벤트 발생순서를 역으로 불러오는것을 사후확률\n",
        "\n",
        "확률할때 4가지는 꼭 왜워야한다\n",
        "\n",
        "상자는 A가 선택될 확률은?\n",
        "\n",
        "사전확률 이벤트 앞단에 나올확률\n",
        "\n",
        "P(X=A)=P(A)=7/10\n",
        "\n",
        "상자는 a가 선택된 상태에서 공은 흰공이 뽑힐 확률은?\n",
        "\n",
        "조건부 확률 P(Y=흰공|X=A)=P(흰공|A)=2/10\n",
        "\n",
        "뒤가 주어졌을때 앞단이 나올확률\n",
        "\n",
        "상자는 A가 선택되고 /그리고 공은 흰 공이 ㅂ뽑힐 확률?\n",
        "\n",
        "결합 확률 P(A,흰공)=P(흰공|A)P(A)=(2/10)(7/10)=7/50\n",
        "\n",
        "두가지 확률을 다본다고 해서 결합확률\n",
        "\n",
        "상자가 a가 선택된 상태 - 사전확률\n",
        "\n",
        "공은 흰공이 뽑힐 확률 - 조건부 확률\n",
        "\n",
        "흰공이 나올 확률은?\n",
        "\n",
        "A,B의 결합확률을 구해서 이두개를 결합한다\n",
        "\n",
        "이것을 주변확률이라고 한다 \n",
        "\n",
        "주변확률 적을때 사전확률과 같다 \n",
        "\n",
        "P라고 적은다음에 사전확률이라고 오해하는데\n",
        "\n",
        "이벤트 발생순서를 봐라 앞단을 물어보면 사전확률\n",
        "\n",
        "뒷단이 나온다면 주변확률 \n",
        "\n",
        "이것을 가지고 사후확률을 추적하여보자\n",
        "\n",
        "흰공이 뽑혔는데 어느 상자에서 나왔는지 추적하시오\n",
        "\n",
        "조건부 확률 구하면 B에서 나올 확률이 나온다\n",
        "\n",
        "두번째 제안\n",
        "\n",
        "사전확률을 먼저 보자 B가 나올 확률이 얼마일지 알수가 없기 때문에\n",
        "\n",
        "앞단을 먼저 확인해보자\n",
        "\n",
        "베이지 정리\n",
        "\n",
        "P(B|A)= A교집합B => p(A)/P(A교집합B)\n",
        "\n",
        "=\n",
        "\n",
        "P(B|A)= A교집합B => p(A)/P(A교집합B)\n",
        "\n",
        "흰공이 주어졌을때 A에서 나올확률\n"
      ],
      "metadata": {
        "id": "vSg0OdhWrD1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15th\n",
        "\n",
        "E로 끝나는것은 모두 error이다\n",
        "\n",
        "작은수로 나오는것이 좋은것이다\n",
        "\n",
        "혼동행렬\n",
        "\n",
        "기준은 항상 내가만든모델이 기준\n",
        "\n",
        "셋다 숫자가 클수록 좋다 정확률, 재현률, f measure(f1 score)\n",
        "\n",
        "정확도란 개념을 왜 안쓰느냐\n",
        "\n",
        "리스크나 코스트를 고려하지 않기 때문에 정확도(Accuracy)를 안쓴다\n",
        "\n",
        "실제데이터는 한쪽으로 쏠려있을 가능성이 크다(편중된 데이터)\n",
        "\n",
        "그렇기 때문에 훈동행렬을 통해서\n",
        "\n",
        "기대값 통계학에서 기대값은 평균값 \n",
        "\n",
        "여기서 말하는 기대값의 의미는 가치와 가중치를 곱해준것\n",
        "\n",
        "여기서 말하는 가중치는 어떤일이 발생할 확률\n",
        "\n",
        "기대값을 가지고\n",
        "1 내가 만든 모델을 누가한테 적용할 것인가\n",
        "\n",
        "2 모델 자체의 성능을 평가할때 기대값을 쓴다\n",
        "\n",
        "확률=전체/나\n",
        "\n",
        "매트릭스의 행은 내가만든모델 열은 타켓\n",
        "\n"
      ],
      "metadata": {
        "id": "ksCwG_YJwNoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16th\n",
        "\n",
        "최적화 알고리즘, 앤트 알고리즘\n",
        "\n",
        "생태계 모방 알고리즘 그중에서도 \n",
        "\n",
        "우성 알고리즘 중에서 Genetic Algorithm\n",
        "\n",
        "미분기반의 알고리즘은 시작하는 위치가 결정되면 \n",
        "\n",
        "방향성이 결정됨 \n",
        "\n",
        "Local Minima - 지역 최대한\n",
        "\n",
        "수학 알고리즘은 시작이 정해지면 방향성이 정해짐\n",
        "\n",
        "그렇지만 Genetic Algorithm 으로 어느정도 조정이 가능함\n",
        "\n",
        "휴리스틱- 어림잡아... 대략적인\n",
        "\n",
        "수학적으로 접근할 수 없다\n",
        "\n",
        "병렬적 탐색\n",
        "\n",
        "약점은? 오랜시간 학습하는데 잘 안나온다면 분석가의 실력\n",
        "\n",
        "Gene 각각의 열정보\n",
        "\n",
        "chromosome(istance) 한행정보\n",
        "\n",
        "population 한세대의 염색체 수 \n",
        "\n",
        "0과 1로 데이터로 받는다 \n",
        "\n",
        "0과 1로 받는 형태를 유전자형(Genotype)\n",
        "\n",
        "우리같은 말의 데이터는 표현형 (Phenotype)\n",
        "\n",
        "우성의 형태를 다음세대로 넘기면서 최적화가 이루어짐\n",
        "\n",
        "거리의 합이 작으면 우성 크면 열성\n",
        "\n",
        "적합도 함수(피트니스펑션이나 오브젝트 펑션은)우성과 열성을\n",
        "\n",
        "나눈다\n",
        "\n",
        "셀렉션을한다 결혼할 두 사람을 뽑는다 \n",
        "\n",
        "1등과 2등을 뽑게되면 오버피팅이 일어나서 데이터가 대충나온다\n",
        "\n",
        "SELECTION연산 부모가 될 연산을 고르는것\n",
        "\n",
        "단순교차\n",
        "\n",
        "크로스오버, 교차\n",
        "\n",
        "복수점 교차\n",
        "\n",
        "뮤테이션이 많을수록 시간이 오래걸린다\n",
        "\n",
        "대신에 다양성이 늘어난다\n",
        "\n",
        "대치연산\n",
        "\n",
        "적합도는 어떻게 \n"
      ],
      "metadata": {
        "id": "8wRQePofCBPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17th\n",
        "\n",
        "일반직군으로 접근하되 이력을 쌓고 데이터 분석도 같이 \n",
        "\n",
        "병행하여라.  데이터분석은 석박사를 대부분 채용한다\n",
        "\n",
        "델은 옜날 용산처럼 표준모델이 있고 거기서 자기에 맞게\n",
        "\n",
        "스펙을 조절을 하였다. 그래서 온라인이 생기자마자 오프라인을 \n",
        "\n",
        "거의 없앴다. \n",
        "\n",
        "컴텍\n",
        "\n",
        "컴텍은 컴퓨터를 구매하면 그 컴퓨터의 구매한부분만 입력되어서 \n",
        "\n",
        "델이 조금 더 데이터분석 잘했다고한다\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6nELMKPuK_zU"
      }
    }
  ]
}